{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-13T05:55:56.906763Z",
     "iopub.status.busy": "2021-07-13T05:55:56.906123Z",
     "iopub.status.idle": "2021-07-13T05:56:40.138890Z",
     "shell.execute_reply": "2021-07-13T05:56:40.138015Z",
     "shell.execute_reply.started": "2021-07-13T05:55:56.906712Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "INPUT_PATH = './data/ieee-fraud-detection/'\n",
    "train_identity_df = pd.read_csv(INPUT_PATH+'train_identity.csv', index_col='TransactionID')\n",
    "train_transaction_df = pd.read_csv(INPUT_PATH+'train_transaction.csv', index_col='TransactionID')\n",
    "test_identity_df = pd.read_csv(INPUT_PATH+'test_identity.csv', index_col='TransactionID')\n",
    "test_transaction_df = pd.read_csv(INPUT_PATH+'test_transaction.csv', index_col='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T05:56:44.756422Z",
     "iopub.status.busy": "2021-07-13T05:56:44.755840Z",
     "iopub.status.idle": "2021-07-13T05:56:44.762017Z",
     "shell.execute_reply": "2021-07-13T05:56:44.761041Z",
     "shell.execute_reply.started": "2021-07-13T05:56:44.756384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((144233, 40), (590540, 393))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_identity_df.shape, train_transaction_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    # 输入表格的每列\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### identity表字符串特征值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_identity_df.columns = train_identity_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T05:58:05.806362Z",
     "iopub.status.busy": "2021-07-13T05:58:05.805867Z",
     "iopub.status.idle": "2021-07-13T05:58:05.862446Z",
     "shell.execute_reply": "2021-07-13T05:58:05.861357Z",
     "shell.execute_reply.started": "2021-07-13T05:58:05.806329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_12</th>\n",
       "      <th>id_15</th>\n",
       "      <th>id_16</th>\n",
       "      <th>id_23</th>\n",
       "      <th>id_27</th>\n",
       "      <th>id_28</th>\n",
       "      <th>id_29</th>\n",
       "      <th>id_30</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransactionID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3663586</th>\n",
       "      <td>NotFound</td>\n",
       "      <td>New</td>\n",
       "      <td>NotFound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New</td>\n",
       "      <td>NotFound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrome 67.0 for android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>mobile</td>\n",
       "      <td>MYA-L13 Build/HUAWEIMYA-L13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663588</th>\n",
       "      <td>Found</td>\n",
       "      <td>Found</td>\n",
       "      <td>Found</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Found</td>\n",
       "      <td>Found</td>\n",
       "      <td>Android 6.0.1</td>\n",
       "      <td>chrome 67.0 for android</td>\n",
       "      <td>1280x720</td>\n",
       "      <td>match_status:2</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>mobile</td>\n",
       "      <td>LGLS676 Build/MXB48T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663597</th>\n",
       "      <td>NotFound</td>\n",
       "      <td>New</td>\n",
       "      <td>NotFound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New</td>\n",
       "      <td>NotFound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ie 11.0 for tablet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>desktop</td>\n",
       "      <td>Trident/7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663601</th>\n",
       "      <td>NotFound</td>\n",
       "      <td>Found</td>\n",
       "      <td>Found</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Found</td>\n",
       "      <td>Found</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrome 67.0 for android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>mobile</td>\n",
       "      <td>MYA-L13 Build/HUAWEIMYA-L13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663602</th>\n",
       "      <td>NotFound</td>\n",
       "      <td>New</td>\n",
       "      <td>NotFound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New</td>\n",
       "      <td>NotFound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrome 67.0 for android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>mobile</td>\n",
       "      <td>SM-G9650 Build/R16NW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170230</th>\n",
       "      <td>NotFound</td>\n",
       "      <td>New</td>\n",
       "      <td>NotFound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New</td>\n",
       "      <td>NotFound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrome 71.0 for android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>mobile</td>\n",
       "      <td>SM-J700M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170233</th>\n",
       "      <td>NotFound</td>\n",
       "      <td>Found</td>\n",
       "      <td>Found</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Found</td>\n",
       "      <td>Found</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrome 71.0 for android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>mobile</td>\n",
       "      <td>SM-J320M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170234</th>\n",
       "      <td>NotFound</td>\n",
       "      <td>New</td>\n",
       "      <td>NotFound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New</td>\n",
       "      <td>NotFound</td>\n",
       "      <td>iOS 10.3.3</td>\n",
       "      <td>mobile safari 10.0</td>\n",
       "      <td>1334x750</td>\n",
       "      <td>match_status:2</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>mobile</td>\n",
       "      <td>iOS Device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170236</th>\n",
       "      <td>NotFound</td>\n",
       "      <td>New</td>\n",
       "      <td>NotFound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New</td>\n",
       "      <td>NotFound</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chrome 43.0 for android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>mobile</td>\n",
       "      <td>ALE-L23 Build/HuaweiALE-L23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170239</th>\n",
       "      <td>NotFound</td>\n",
       "      <td>Found</td>\n",
       "      <td>Found</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Found</td>\n",
       "      <td>Found</td>\n",
       "      <td>NaN</td>\n",
       "      <td>samsung browser 8.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>mobile</td>\n",
       "      <td>SAMSUNG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141907 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id_12  id_15     id_16 id_23 id_27  id_28     id_29  \\\n",
       "TransactionID                                                           \n",
       "3663586        NotFound    New  NotFound   NaN   NaN    New  NotFound   \n",
       "3663588           Found  Found     Found   NaN   NaN  Found     Found   \n",
       "3663597        NotFound    New  NotFound   NaN   NaN    New  NotFound   \n",
       "3663601        NotFound  Found     Found   NaN   NaN  Found     Found   \n",
       "3663602        NotFound    New  NotFound   NaN   NaN    New  NotFound   \n",
       "...                 ...    ...       ...   ...   ...    ...       ...   \n",
       "4170230        NotFound    New  NotFound   NaN   NaN    New  NotFound   \n",
       "4170233        NotFound  Found     Found   NaN   NaN  Found     Found   \n",
       "4170234        NotFound    New  NotFound   NaN   NaN    New  NotFound   \n",
       "4170236        NotFound    New  NotFound   NaN   NaN    New  NotFound   \n",
       "4170239        NotFound  Found     Found   NaN   NaN  Found     Found   \n",
       "\n",
       "                       id_30                    id_31     id_33  \\\n",
       "TransactionID                                                     \n",
       "3663586                  NaN  chrome 67.0 for android       NaN   \n",
       "3663588        Android 6.0.1  chrome 67.0 for android  1280x720   \n",
       "3663597                  NaN       ie 11.0 for tablet       NaN   \n",
       "3663601                  NaN  chrome 67.0 for android       NaN   \n",
       "3663602                  NaN  chrome 67.0 for android       NaN   \n",
       "...                      ...                      ...       ...   \n",
       "4170230                  NaN  chrome 71.0 for android       NaN   \n",
       "4170233                  NaN  chrome 71.0 for android       NaN   \n",
       "4170234           iOS 10.3.3       mobile safari 10.0  1334x750   \n",
       "4170236                  NaN  chrome 43.0 for android       NaN   \n",
       "4170239                  NaN      samsung browser 8.2       NaN   \n",
       "\n",
       "                        id_34 id_35 id_36 id_37 id_38 DeviceType  \\\n",
       "TransactionID                                                      \n",
       "3663586                   NaN     F     F     T     F     mobile   \n",
       "3663588        match_status:2     T     F     T     T     mobile   \n",
       "3663597                   NaN     F     T     T     F    desktop   \n",
       "3663601                   NaN     F     F     T     F     mobile   \n",
       "3663602                   NaN     F     F     T     F     mobile   \n",
       "...                       ...   ...   ...   ...   ...        ...   \n",
       "4170230                   NaN     F     F     T     F     mobile   \n",
       "4170233                   NaN     F     F     T     F     mobile   \n",
       "4170234        match_status:2     T     F     F     T     mobile   \n",
       "4170236                   NaN     F     F     T     F     mobile   \n",
       "4170239                   NaN     F     F     T     F     mobile   \n",
       "\n",
       "                                DeviceInfo  \n",
       "TransactionID                               \n",
       "3663586        MYA-L13 Build/HUAWEIMYA-L13  \n",
       "3663588               LGLS676 Build/MXB48T  \n",
       "3663597                        Trident/7.0  \n",
       "3663601        MYA-L13 Build/HUAWEIMYA-L13  \n",
       "3663602               SM-G9650 Build/R16NW  \n",
       "...                                    ...  \n",
       "4170230                           SM-J700M  \n",
       "4170233                           SM-J320M  \n",
       "4170234                         iOS Device  \n",
       "4170236        ALE-L23 Build/HuaweiALE-L23  \n",
       "4170239                            SAMSUNG  \n",
       "\n",
       "[141907 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_identity_df.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T06:04:20.041809Z",
     "iopub.status.busy": "2021-07-13T06:04:20.041176Z",
     "iopub.status.idle": "2021-07-13T06:04:20.061408Z",
     "shell.execute_reply": "2021-07-13T06:04:20.060490Z",
     "shell.execute_reply.started": "2021-07-13T06:04:20.041758Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "def id_split(dataframe):\n",
    "    dataframe['device_name'] = dataframe['DeviceInfo'].str.split('/', expand=True)[0]\n",
    "    dataframe['device_version'] = dataframe['DeviceInfo'].str.split('/', expand=True)[1]\n",
    "\n",
    "    dataframe['OS_id_30'] = dataframe['id_30'].str.split(' ', expand=True)[0]\n",
    "    dataframe['version_id_30'] = dataframe['id_30'].str.split(' ', expand=True)[1]\n",
    "\n",
    "    dataframe['browser_id_31'] = dataframe['id_31'].str.split(' ', expand=True)[0]\n",
    "    dataframe['version_id_31'] = dataframe['id_31'].str.split(' ', expand=True)[1]\n",
    "\n",
    "    dataframe['screen_width'] = dataframe['id_33'].str.split('x', expand=True)[0]\n",
    "    dataframe['screen_height'] = dataframe['id_33'].str.split('x', expand=True)[1]\n",
    "\n",
    "    dataframe['id_34'] = dataframe['id_34'].str.split(':', expand=True)[1]\n",
    "    dataframe['id_23'] = dataframe['id_23'].str.split(':', expand=True)[1]\n",
    "\n",
    "    # 聚合\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('SM', na=False), 'device_name'] = 'Samsung'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('SAMSUNG', na=False), 'device_name'] = 'Samsung'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('GT-', na=False), 'device_name'] = 'Samsung'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Moto G', na=False), 'device_name'] = 'Motorola'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Moto', na=False), 'device_name'] = 'Motorola'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('moto', na=False), 'device_name'] = 'Motorola'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('LG-', na=False), 'device_name'] = 'LG'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('rv:', na=False), 'device_name'] = 'RV'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('HUAWEI', na=False), 'device_name'] = 'Huawei'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('ALE-', na=False), 'device_name'] = 'Huawei'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('-L', na=False), 'device_name'] = 'Huawei'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Blade', na=False), 'device_name'] = 'ZTE'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('BLADE', na=False), 'device_name'] = 'ZTE'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('Linux', na=False), 'device_name'] = 'Linux'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('XT', na=False), 'device_name'] = 'Sony'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('HTC', na=False), 'device_name'] = 'HTC'\n",
    "    dataframe.loc[dataframe['device_name'].str.contains('ASUS', na=False), 'device_name'] = 'Asus'\n",
    "\n",
    "    dataframe.loc[dataframe.device_name.isin(dataframe.device_name.value_counts()[dataframe.device_name.value_counts() < 200].index), 'device_name'] = \"Others\"\n",
    "    dataframe['had_id'] = 1\n",
    "    gc.collect()\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T06:04:39.365055Z",
     "iopub.status.busy": "2021-07-13T06:04:39.364674Z",
     "iopub.status.idle": "2021-07-13T06:04:46.467580Z",
     "shell.execute_reply": "2021-07-13T06:04:46.466200Z",
     "shell.execute_reply.started": "2021-07-13T06:04:39.365022Z"
    }
   },
   "outputs": [],
   "source": [
    "train_identity = id_split(train_identity_df)\n",
    "test_identity = id_split(test_identity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train_transaction_df.merge(train_identity, how='left', left_index=True, right_index=True)\n",
    "test = test_transaction_df.merge(test_identity, how='left', left_index=True, right_index=True)\n",
    "\n",
    "# 删除原始数据\n",
    "del train_identity_df, test_identity_df, train_identity, test_identity, train_transaction_df, test_transaction_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((590540, 442), (506691, 441))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过 null importance 筛选特征\n",
    "useful_features = ['TransactionAmt', 'ProductCD', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'addr1', 'addr2', 'dist1',\n",
    "                   'P_emaildomain', 'R_emaildomain', 'C1', 'C2', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13',\n",
    "                   'C14', 'D1', 'D2', 'D3', 'D4', 'D5', 'D6', 'D8', 'D9', 'D10', 'D11', 'D12', 'D13', 'D14', 'D15', 'M2', 'M3',\n",
    "                   'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V17',\n",
    "                   'V19', 'V20', 'V29', 'V30', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V40', 'V44', 'V45', 'V46', 'V47', 'V48',\n",
    "                   'V49', 'V51', 'V52', 'V53', 'V54', 'V56', 'V58', 'V59', 'V60', 'V61', 'V62', 'V63', 'V64', 'V69', 'V70', 'V71',\n",
    "                   'V72', 'V73', 'V74', 'V75', 'V76', 'V78', 'V80', 'V81', 'V82', 'V83', 'V84', 'V85', 'V87', 'V90', 'V91', 'V92',\n",
    "                   'V93', 'V94', 'V95', 'V96', 'V97', 'V99', 'V100', 'V126', 'V127', 'V128', 'V130', 'V131', 'V138', 'V139', 'V140',\n",
    "                   'V143', 'V145', 'V146', 'V147', 'V149', 'V150', 'V151', 'V152', 'V154', 'V156', 'V158', 'V159', 'V160', 'V161',\n",
    "                   'V162', 'V163', 'V164', 'V165', 'V166', 'V167', 'V169', 'V170', 'V171', 'V172', 'V173', 'V175', 'V176', 'V177',\n",
    "                   'V178', 'V180', 'V182', 'V184', 'V187', 'V188', 'V189', 'V195', 'V197', 'V200', 'V201', 'V202', 'V203', 'V204',\n",
    "                   'V205', 'V206', 'V207', 'V208', 'V209', 'V210', 'V212', 'V213', 'V214', 'V215', 'V216', 'V217', 'V219', 'V220',\n",
    "                   'V221', 'V222', 'V223', 'V224', 'V225', 'V226', 'V227', 'V228', 'V229', 'V231', 'V233', 'V234', 'V238', 'V239',\n",
    "                   'V242', 'V243', 'V244', 'V245', 'V246', 'V247', 'V249', 'V251', 'V253', 'V256', 'V257', 'V258', 'V259', 'V261',\n",
    "                   'V262', 'V263', 'V264', 'V265', 'V266', 'V267', 'V268', 'V270', 'V271', 'V272', 'V273', 'V274', 'V275', 'V276',\n",
    "                   'V277', 'V278', 'V279', 'V280', 'V282', 'V283', 'V285', 'V287', 'V288', 'V289', 'V291', 'V292', 'V294', 'V303',\n",
    "                   'V304', 'V306', 'V307', 'V308', 'V310', 'V312', 'V313', 'V314', 'V315', 'V317', 'V322', 'V323', 'V324', 'V326',\n",
    "                   'V329', 'V331', 'V332', 'V333', 'V335', 'V336', 'V338', 'id_01', 'id_02', 'id_03', 'id_05', 'id_06', 'id_09',\n",
    "                   'id_11', 'id_12', 'id_13', 'id_14', 'id_15', 'id_17', 'id_19', 'id_20', 'id_30', 'id_31', 'id_32', 'id_33',\n",
    "                   'id_36', 'id_37', 'id_38', 'DeviceType', 'DeviceInfo', 'device_name', 'device_version', 'OS_id_30', 'version_id_30',\n",
    "                   'browser_id_31', 'version_id_31', 'screen_width', 'screen_height', 'had_id']\n",
    "\n",
    "cols_to_drop = [col for col in train.columns if col not in useful_features]\n",
    "cols_to_drop.remove('isFraud')\n",
    "cols_to_drop.remove('TransactionDT')\n",
    "\n",
    "train = train.drop(cols_to_drop, axis=1)\n",
    "test = test.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((590540, 290), (506691, 289))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数值特征处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_a = ['TransactionAmt', 'id_02', 'D15']\n",
    "columns_b = ['card1', 'card4', 'addr1']\n",
    "# card1相同的样本组中，transactionAmt的平均值\n",
    "# df['TransactionAmt_groupby_card1'] = df['TransactionAmt'] / df.groupby('card1')['TransactionAmt'].mean()\n",
    "\n",
    "for col_a in columns_a:\n",
    "    for col_b in columns_b:\n",
    "        for df in [train, test]:\n",
    "            df[f'{col_a}_to_mean_{col_b}'] = df[col_a] / df.groupby([col_b])[col_a].transform('mean')\n",
    "            df[f'{col_a}_to_std_{col_b}'] = df[col_a] / df.groupby([col_b])[col_a].transform('std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log of transaction amount.\n",
    "# 对交易金额取log，使得长尾分布更加正态分布，让方差稳定，把目标关注在其波动之上\n",
    "train['TransactionAmt_Log'] = np.log(train['TransactionAmt'])\n",
    "test['TransactionAmt_Log'] = np.log(test['TransactionAmt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decimal part of the transaction amount.\n",
    "# 截取交易金额小数部分的值，因为在小数部分的信息比较多\n",
    "train['TransactionAmt_decimal'] = ((train['TransactionAmt'] - train['TransactionAmt'].astype(int)) * 1000).astype(int)\n",
    "test['TransactionAmt_decimal'] = ((test['TransactionAmt'] - test['TransactionAmt'].astype(int)) * 1000).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day of week in which a transaction happened.\n",
    "train['Transaction_day_of_week'] = np.floor((train['TransactionDT'] / (3600 * 24) - 1) % 7)\n",
    "test['Transaction_day_of_week'] = np.floor((test['TransactionDT'] / (3600 * 24) - 1) % 7)\n",
    "# hour of the day in which a transaction happened.\n",
    "train['Transaction_hour'] = np.floor(train['TransactionDT'] / 3600) % 24\n",
    "test['Transaction_hour'] = np.floor(test['TransactionDT'] / 3600) % 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features interaction\n",
    "# 将强相关的特征和合并，并转化为数值表示\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for feature in ['id_02__id_20', 'id_02__D8', 'D11__DeviceInfo', 'DeviceInfo__P_emaildomain', 'P_emaildomain__C2', \n",
    "                'card2__dist1', 'card1__card5', 'card2__id_20', 'card5__P_emaildomain', 'addr1__card1']:\n",
    "\n",
    "    f1, f2 = feature.split('__')\n",
    "    train[feature] = train[f1].astype(str) + '_' + train[f2].astype(str)\n",
    "    test[feature] = test[f1].astype(str) + '_' + test[f2].astype(str)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(train[feature].astype(str).values) + list(test[feature].astype(str).values))\n",
    "    train[feature] = le.transform(list(train[feature].astype(str).values))\n",
    "    test[feature] = le.transform(list(test[feature].astype(str).values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count encoding 将类别特征值转化为特征出现的次数\n",
    "# count encoding for both train and test\n",
    "for feature in ['card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'id_36']:\n",
    "    train[feature + '_count_full'] = train[feature].map(pd.concat([train[feature], test[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "    test[feature + '_count_full'] = test[feature].map(pd.concat([train[feature], test[feature]], ignore_index=True).value_counts(dropna=False))\n",
    "\n",
    "# count encoding separately for train and test\n",
    "for feature in ['id_01', 'id_31', 'id_33', 'id_36']:\n",
    "    train[feature + '_count_dist'] = train[feature].map(train[feature].value_counts(dropna=False))\n",
    "    test[feature + '_count_dist'] = test[feature].map(test[feature].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理email特征\n",
    "\n",
    "emails = {'gmail': 'google', 'att.net': 'att', 'twc.com': 'spectrum', 'scranton.edu': 'other', 'optonline.net': 'other', 'hotmail.co.uk': 'microsoft', 'comcast.net': 'other', 'yahoo.com.mx': 'yahoo', 'yahoo.fr': 'yahoo', 'yahoo.es': 'yahoo', 'charter.net': 'spectrum', 'live.com': 'microsoft', 'aim.com': 'aol', 'hotmail.de': 'microsoft', 'centurylink.net': 'centurylink', 'gmail.com': 'google', 'me.com': 'apple', 'earthlink.net': 'other', 'gmx.de': 'other', 'web.de': 'other', 'cfl.rr.com': 'other', 'hotmail.com': 'microsoft', 'protonmail.com': 'other', 'hotmail.fr': 'microsoft', 'windstream.net': 'other', 'outlook.es': 'microsoft', 'yahoo.co.jp': 'yahoo', 'yahoo.de': 'yahoo', 'servicios-ta.com': 'other', 'netzero.net': 'other', 'suddenlink.net': 'other', 'roadrunner.com': 'other', 'sc.rr.com': 'other', 'live.fr': 'microsoft', 'verizon.net': 'yahoo', 'msn.com': 'microsoft', 'q.com': 'centurylink', 'prodigy.net.mx': 'att', 'frontier.com': 'yahoo', 'anonymous.com': 'other', 'rocketmail.com': 'yahoo', 'sbcglobal.net': 'att', 'frontiernet.net': 'yahoo', 'ymail.com': 'yahoo', 'outlook.com': 'microsoft', 'mail.com': 'other', 'bellsouth.net': 'other', 'embarqmail.com': 'centurylink', 'cableone.net': 'other', 'hotmail.es': 'microsoft', 'mac.com': 'apple', 'yahoo.co.uk': 'yahoo', 'netzero.com': 'other', 'yahoo.com': 'yahoo', 'live.com.mx': 'microsoft', 'ptd.net': 'other', 'cox.net': 'other', 'aol.com': 'aol', 'juno.com': 'other', 'icloud.com': 'apple'}\n",
    "us_emails = ['gmail', 'net', 'edu']\n",
    "\n",
    "for c in ['P_emaildomain', 'R_emaildomain']:\n",
    "    train[c + '_bin'] = train[c].map(emails)\n",
    "    test[c + '_bin'] = test[c].map(emails)\n",
    "    \n",
    "    train[c + '_suffix'] = train[c].map(lambda x: str(x).split('.')[-1])\n",
    "    test[c + '_suffix'] = test[c].map(lambda x: str(x).split('.')[-1])\n",
    "    \n",
    "    train[c + '_suffix'] = train[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')\n",
    "    test[c + '_suffix'] = test[c + '_suffix'].map(lambda x: x if str(x) not in us_emails else 'us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将所有类别特征转化为数值\n",
    "\n",
    "for col in train.columns:\n",
    "    if train[col].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n",
    "        train[col] = le.transform(list(train[col].astype(str).values))\n",
    "        test[col] = le.transform(list(test[col].astype(str).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1542.85 MB\n",
      "Memory usage after optimization is: 451.40 MB\n",
      "Decreased by 70.7%\n",
      "Memory usage of dataframe is 1322.76 MB\n",
      "Memory usage after optimization is: 400.29 MB\n",
      "Decreased by 69.7%\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.sort_values('TransactionDT').drop(['isFraud', 'TransactionDT'], axis=1)\n",
    "y = train.sort_values('TransactionDT')['isFraud']\n",
    "\n",
    "X_test = test.drop(['TransactionDT'], axis=1)\n",
    "\n",
    "del train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "params = {'num_leaves': 491,\n",
    "          'min_child_weight': 0.03454472573214212,\n",
    "          'feature_fraction': 0.3797454081646243,\n",
    "          'bagging_fraction': 0.4181193142567742,\n",
    "          'min_data_in_leaf': 106,\n",
    "          'objective': 'binary',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.006883242363721497,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'auc',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.3899927210061127,\n",
    "          'reg_lambda': 0.6485237330340494,\n",
    "          'random_state': 47,\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's auc: 0.956126\tvalid_1's auc: 0.932567\n",
      "[400]\ttraining's auc: 0.977744\tvalid_1's auc: 0.948903\n",
      "[600]\ttraining's auc: 0.990007\tvalid_1's auc: 0.959692\n",
      "[800]\ttraining's auc: 0.995714\tvalid_1's auc: 0.965034\n",
      "[1000]\ttraining's auc: 0.998293\tvalid_1's auc: 0.96775\n",
      "[1200]\ttraining's auc: 0.999349\tvalid_1's auc: 0.969469\n",
      "[1400]\ttraining's auc: 0.99975\tvalid_1's auc: 0.970532\n",
      "[1600]\ttraining's auc: 0.999903\tvalid_1's auc: 0.971348\n",
      "[1800]\ttraining's auc: 0.999967\tvalid_1's auc: 0.971796\n",
      "[2000]\ttraining's auc: 0.99999\tvalid_1's auc: 0.972166\n",
      "[2200]\ttraining's auc: 0.999997\tvalid_1's auc: 0.972374\n",
      "[2400]\ttraining's auc: 0.999999\tvalid_1's auc: 0.972503\n",
      "[2600]\ttraining's auc: 1\tvalid_1's auc: 0.972629\n",
      "[2800]\ttraining's auc: 1\tvalid_1's auc: 0.972664\n",
      "[3000]\ttraining's auc: 1\tvalid_1's auc: 0.972707\n",
      "[3200]\ttraining's auc: 1\tvalid_1's auc: 0.972676\n",
      "[3400]\ttraining's auc: 1\tvalid_1's auc: 0.972629\n",
      "Early stopping, best iteration is:\n",
      "[2975]\ttraining's auc: 1\tvalid_1's auc: 0.972718\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "dvalid = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "clf = lgb.train(params, dtrain, 10000, valid_sets = [dtrain, dvalid], verbose_eval=200, early_stopping_rounds=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = clf.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9727178962329261"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_valid, y_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transaction_df = pd.read_csv(INPUT_PATH+'test_transaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({'TransactionID': test_transaction_df['TransactionID'].values, \n",
    "                          'isFraud': y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(INPUT_PATH+'result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's auc: 0.956091\tvalid_1's auc: 0.889799\n",
      "[400]\ttraining's auc: 0.977275\tvalid_1's auc: 0.903277\n",
      "[600]\ttraining's auc: 0.989162\tvalid_1's auc: 0.911361\n",
      "[800]\ttraining's auc: 0.994896\tvalid_1's auc: 0.916082\n",
      "[1000]\ttraining's auc: 0.99763\tvalid_1's auc: 0.918576\n",
      "[1200]\ttraining's auc: 0.998883\tvalid_1's auc: 0.919955\n",
      "[1400]\ttraining's auc: 0.99948\tvalid_1's auc: 0.920801\n",
      "[1600]\ttraining's auc: 0.999755\tvalid_1's auc: 0.920903\n",
      "[1800]\ttraining's auc: 0.999886\tvalid_1's auc: 0.921094\n",
      "[2000]\ttraining's auc: 0.999951\tvalid_1's auc: 0.921204\n",
      "[2200]\ttraining's auc: 0.999979\tvalid_1's auc: 0.921449\n",
      "[2400]\ttraining's auc: 0.999991\tvalid_1's auc: 0.92157\n",
      "[2600]\ttraining's auc: 0.999996\tvalid_1's auc: 0.921941\n",
      "[2800]\ttraining's auc: 0.999998\tvalid_1's auc: 0.922092\n",
      "[3000]\ttraining's auc: 0.999999\tvalid_1's auc: 0.922207\n",
      "[3200]\ttraining's auc: 1\tvalid_1's auc: 0.922229\n",
      "[3400]\ttraining's auc: 1\tvalid_1's auc: 0.922212\n",
      "[3600]\ttraining's auc: 1\tvalid_1's auc: 0.922091\n",
      "Early stopping, best iteration is:\n",
      "[3253]\ttraining's auc: 1\tvalid_1's auc: 0.922292\n",
      "Fold 1 | AUC: 0.9222924662920489\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's auc: 0.955654\tvalid_1's auc: 0.91002\n",
      "[400]\ttraining's auc: 0.977218\tvalid_1's auc: 0.921852\n",
      "[600]\ttraining's auc: 0.989716\tvalid_1's auc: 0.929987\n",
      "[800]\ttraining's auc: 0.995561\tvalid_1's auc: 0.934116\n",
      "[1000]\ttraining's auc: 0.998179\tvalid_1's auc: 0.935984\n",
      "[1200]\ttraining's auc: 0.999225\tvalid_1's auc: 0.93691\n",
      "[1400]\ttraining's auc: 0.999673\tvalid_1's auc: 0.937329\n",
      "[1600]\ttraining's auc: 0.999859\tvalid_1's auc: 0.937488\n",
      "[1800]\ttraining's auc: 0.99994\tvalid_1's auc: 0.937469\n",
      "[2000]\ttraining's auc: 0.999977\tvalid_1's auc: 0.937343\n",
      "Early stopping, best iteration is:\n",
      "[1548]\ttraining's auc: 0.999823\tvalid_1's auc: 0.937544\n",
      "Fold 2 | AUC: 0.9375444812900033\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's auc: 0.957264\tvalid_1's auc: 0.910513\n",
      "[400]\ttraining's auc: 0.97814\tvalid_1's auc: 0.923542\n",
      "[600]\ttraining's auc: 0.989925\tvalid_1's auc: 0.931106\n",
      "[800]\ttraining's auc: 0.995517\tvalid_1's auc: 0.934188\n",
      "[1000]\ttraining's auc: 0.998106\tvalid_1's auc: 0.935081\n",
      "[1200]\ttraining's auc: 0.999193\tvalid_1's auc: 0.935268\n",
      "[1400]\ttraining's auc: 0.999655\tvalid_1's auc: 0.935026\n",
      "[1600]\ttraining's auc: 0.999849\tvalid_1's auc: 0.934889\n",
      "Early stopping, best iteration is:\n",
      "[1126]\ttraining's auc: 0.998913\tvalid_1's auc: 0.935373\n",
      "Fold 3 | AUC: 0.9353727075212284\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's auc: 0.954988\tvalid_1's auc: 0.925801\n",
      "[400]\ttraining's auc: 0.976755\tvalid_1's auc: 0.938875\n",
      "[600]\ttraining's auc: 0.989601\tvalid_1's auc: 0.947025\n",
      "[800]\ttraining's auc: 0.995411\tvalid_1's auc: 0.950395\n",
      "[1000]\ttraining's auc: 0.998097\tvalid_1's auc: 0.951693\n",
      "[1200]\ttraining's auc: 0.999196\tvalid_1's auc: 0.952209\n",
      "[1400]\ttraining's auc: 0.99967\tvalid_1's auc: 0.952389\n",
      "[1600]\ttraining's auc: 0.999862\tvalid_1's auc: 0.952245\n",
      "[1800]\ttraining's auc: 0.999943\tvalid_1's auc: 0.952174\n",
      "Early stopping, best iteration is:\n",
      "[1391]\ttraining's auc: 0.999657\tvalid_1's auc: 0.95239\n",
      "Fold 4 | AUC: 0.9523898079543811\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[200]\ttraining's auc: 0.956246\tvalid_1's auc: 0.90265\n",
      "[400]\ttraining's auc: 0.977009\tvalid_1's auc: 0.91606\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   2641\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2642\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2643\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   2644\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2645\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "NFOLDS = 5\n",
    "folds = KFold(n_splits=NFOLDS)\n",
    "\n",
    "columns = X.columns\n",
    "splits = folds.split(X, y)\n",
    "y_preds = np.zeros(X_test.shape[0])\n",
    "y_oof = np.zeros(X.shape[0])\n",
    "score = 0\n",
    "\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances['feature'] = columns\n",
    "  \n",
    "for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "    X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "    \n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    dvalid = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "    clf = lgb.train(params, dtrain, 10000, valid_sets = [dtrain, dvalid], verbose_eval=200, early_stopping_rounds=500)\n",
    "    \n",
    "    feature_importances[f'fold_{fold_n + 1}'] = clf.feature_importance()\n",
    "    \n",
    "    y_pred_valid = clf.predict(X_valid)\n",
    "    y_oof[valid_index] = y_pred_valid\n",
    "    print(f\"Fold {fold_n + 1} | AUC: {roc_auc_score(y_valid, y_pred_valid)}\")\n",
    "    \n",
    "    score += roc_auc_score(y_valid, y_pred_valid) / NFOLDS\n",
    "    y_preds += clf.predict(X_test) / NFOLDS\n",
    "    \n",
    "    del X_train, X_valid, y_train, y_valid\n",
    "    gc.collect()\n",
    "    \n",
    "print(f\"\\nMean AUC = {score}\")\n",
    "print(f\"Out of folds AUC = {roc_auc_score(y, y_oof)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
